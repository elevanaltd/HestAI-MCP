# HestAI-MCP Environment Configuration
# Copy this file to .env in your project root and add your actual values
#
# This file is automatically loaded by HestAI-MCP on startup.
# API keys and settings configured here will be available to the system.

# =============================================================================
# PROJECT ROOT (Optional - defaults to current working directory)
# =============================================================================

# Control where .hestai-sys/ governance directory is created.
# If not set, defaults to the directory where the MCP server runs (CWD).
# This follows the same pattern as debate-hall's ./debates directory.
#
# Default behavior (no env var):
#   Server runs in /my/project → creates /my/project/.hestai-sys
#   Server runs in /my/project/worktree → creates /my/project/worktree/.hestai-sys
#
# Override with explicit path (optional):
#   HESTAI_PROJECT_ROOT=/path/to/shared/location
#
# Leave commented to use the simple CWD default:
# HESTAI_PROJECT_ROOT=/path/to/your/project

# =============================================================================
# API KEYS (Required - at least one provider)
# =============================================================================

# OpenRouter - Recommended: One key, access to many models including Anthropic
# Get your key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# OpenAI - Direct OpenAI API access
# Get your key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-key

# Note: Anthropic models (Claude) are available via OpenRouter
# Use model names like: anthropic/claude-3.5-sonnet, anthropic/claude-3-opus
# Direct Anthropic API is not currently supported as a provider.

# =============================================================================
# DEFAULT AI SETTINGS (Optional - used when no ai.yaml exists)
# =============================================================================

# Default provider: openrouter or openai
HESTAI_AI_PROVIDER=openrouter

# Default model for synthesis tier (fast, cheap - used by clock_in)
HESTAI_AI_MODEL=google/gemini-2.0-flash-lite

# Model for analysis tier (balanced)
HESTAI_AI_MODEL_ANALYSIS=anthropic/claude-3.5-sonnet

# Model for critical tier (best available)
HESTAI_AI_MODEL_CRITICAL=anthropic/claude-3.5-sonnet

# =============================================================================
# ADVANCED: For full tier customization, create ~/.hestai/config/ai.yaml
# See config/ai.yaml.example for the complete configuration format
# =============================================================================
