# HestAI-MCP AI Configuration
# Copy this file to ~/.hestai/config/ai.yaml
#
# This configures which AI models to use for different tasks.
# API keys are loaded from environment variables or system keyring.

# =============================================================================
# TIERED MODEL CONFIGURATION
# =============================================================================
# Different tiers for different use cases:
# - synthesis: Fast, cheap models for routine tasks (clock_in context generation)
# - analysis: Balanced models for deeper analysis
# - critical: Best available for high-stakes decisions

tiers:
  synthesis:
    provider: openrouter
    model: =google/gemini-3-flash-preview
    description: Fast, cost-effective model for context synthesis

  analysis:
    provider: openrouter
    model: google/gemini-3-pro-preview
    description: Balanced model for deeper analysis

  critical:
    provider: openrouter
    model: google/gemini-3-pro-preview
    description: High-capability model for critical decisions

# Which tier to use by default
default_tier: synthesis

# =============================================================================
# OPERATION TIER MAPPING
# =============================================================================
# Map specific operations to tiers. Operations not listed use default_tier.
# This allows fine-grained control over which model handles each operation.

operations:
  clock_in_synthesis: synthesis   # Fast context generation on session start
  context_update: synthesis       # Context updates during session
  document_analysis: analysis     # Deeper document analysis
  odyssean_anchor_validation: analysis  # Semantic validation of agent binding (Issue #131)

# =============================================================================
# TIMEOUT SETTINGS
# =============================================================================

timeouts:
  connect_seconds: 5
  request_seconds: 30

# =============================================================================
# POPULAR MODEL OPTIONS (for reference)
# =============================================================================
#
# OpenRouter models (use with provider: openrouter):
#   Fast/Cheap:
#     - google/gemini-2.5-flash-lite    # Very fast, very cheap
#     - google/gemini-3-flash-preview   # Fast, cheap
#     - mistralai/mistral-7b-instruct   # Fast, cheap
#
#   Balanced:
#     - anthropic/claude-4.5-sonnet     # Great quality/price balance
#     - openai/gpt-5.2                   # OpenAI's latest
#     - google/gemini-3-pro-preview     # Google's best
#
#   High-capability:
#     - anthropic/claude-opus-4.5       # Highest quality (expensive)
#     - openai/gpt-5.2.                 # OpenAI's best
#
# See full list: https://openrouter.ai/models
#
# =============================================================================
# ODYSSEAN ANCHOR SEMANTIC VALIDATION (Issue #131)
# =============================================================================
# Optional AI-driven semantic validation for agent binding.
# When enabled, validates that TENSION and COMMIT reflect genuine understanding.
# Can be overridden via environment variables:
#   HESTAI_OA_SEMANTIC_VALIDATION=true
#   HESTAI_OA_SEMANTIC_FAIL_MODE=warn

odyssean_anchor:
  semantic_validation:
    enabled: false              # Default off for backward compatibility
    tier: analysis              # Which AI tier to use (synthesis/analysis/critical)
    timeout_seconds: 15         # Max time for semantic validation
    fail_mode: warn             # warn (log only) | block (reject bind)
    checks:
      cognition_appropriateness: true   # Is COGNITION type correct for role?
      tension_relevance: true           # Do TENSIONs cite real constraints?
      ctx_validity: true                # Do CTX paths reference actual files?
      commit_feasibility: true          # Is COMMIT artifact achievable?

# =============================================================================
# ALTERNATIVE: SINGLE PROVIDER SETUP
# =============================================================================
# If you prefer to use a single model for everything, set all tiers to the same:
#
# tiers:
#   synthesis:
#     provider: openrouter
#     model: google/gemini-3-pro-preview
#   analysis:
#     provider: openrouter
#     model: google/gemini-3-pro-preview
#   critical:
#     provider: openrouter
#     model: google/gemini-3-pro-preview
